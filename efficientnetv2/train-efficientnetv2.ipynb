{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-box timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from box import Box\n",
    "from timm import create_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seed': 2021,\n",
    "    'root': '../input/petfinder-pawpularity-score',\n",
    "    'n_splits': 5,\n",
    "    'epochs': 20,\n",
    "    'image_size': 640,\n",
    "    'train_loader': {\n",
    "        'batch_size': 32,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': True,\n",
    "    },\n",
    "    'val_loader': {\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': False,\n",
    "        'drop_last': False,\n",
    "    },\n",
    "    'trainer': {\n",
    "        'gpus': [1, 2, 3],\n",
    "        'accumulate_grad_batches': 1,\n",
    "        'progress_bar_refresh_rate': 1,\n",
    "        'fast_dev_run': False,\n",
    "        'num_sanity_val_steps': 0,\n",
    "        'resume_from_checkpoint': None,\n",
    "    },\n",
    "    'model': {\n",
    "        # EfficientNet\n",
    "        'name': 'tf_efficientnet_b6_ns',\n",
    "        # 'name': 'tf_efficientnet_b7_ns',\n",
    "\n",
    "        # EfficientNetv2\n",
    "        # 'name': 'tf_efficientnetv2_m_in21k',\n",
    "        # 'name': 'tf_efficientnetv2_l_in21k',\n",
    "        'output_dim': 1,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'optim.AdamW',\n",
    "        'params': {\n",
    "            'lr': 1e-5,\n",
    "        },\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "        'params': {\n",
    "            'T_0': 20,\n",
    "            'eta_min': 1e-4,\n",
    "        }\n",
    "    },\n",
    "    'loss': 'nn.BCEWithLogitsLoss',\n",
    "}\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetfinderDataset(Dataset):\n",
    "    def __init__(self, df, image_size=224):\n",
    "        self._X = df[\"Id\"].values\n",
    "        self._y = None\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self._y = df[\"Pawpularity\"].values\n",
    "        self._transform = T.Resize([image_size, image_size])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self._X[idx]\n",
    "        image = read_image(image_path)\n",
    "        image = self._transform(image)\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "class PetfinderDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, cfg):\n",
    "        super().__init__()\n",
    "        self._train_df = train_df\n",
    "        self._val_df = val_df\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def __create_dataset(self, train=True):\n",
    "        return (\n",
    "            PetfinderDataset(self._train_df, self._cfg.image_size)\n",
    "            if train\n",
    "            else PetfinderDataset(self._val_df, self._cfg.image_size)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self.__create_dataset(True)\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self.__create_dataset(False)\n",
    "        return DataLoader(dataset, **self._cfg.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "seed_everything(config.seed)\n",
    "\n",
    "df = pd.read_csv(os.path.join(config.root, \"train.csv\"))\n",
    "df[\"Id\"] = df[\"Id\"].apply(lambda x: os.path.join(config.root, \"train\", x + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "def get_default_transforms():\n",
    "    transform = {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "        ),\n",
    "        \"val\": T.Compose(\n",
    "            [\n",
    "                T.ConvertImageDtype(torch.float),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n",
    "    train_df = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.loc[val_idx].reset_index(drop=True)\n",
    "    dm = PetfinderDataModule(train_df, val_df, config)\n",
    "    model = Model(config)\n",
    "    earlystopping = EarlyStopping(monitor=\"val_loss\")\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filename=\"best_loss\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=False,\n",
    "    )\n",
    "    logger = TensorBoardLogger(config.model.name)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        max_epochs=config.epochs,\n",
    "        callbacks=[lr_monitor, loss_checkpoint, earlystopping],\n",
    "        **config.trainer,\n",
    "    )\n",
    "    trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "path = glob(f'./{config.model.name}/default/version_0/events*')[0]\n",
    "even_acc = EventAccumulator(path, size_guidance={'scalar': 0})\n",
    "even_acc.Reload()\n",
    "\n",
    "scalars = {}\n",
    "for tag in event_acc.Tags()['scalars']:\n",
    "    event = event_acc.Scalars(tag)\n",
    "    scalars[tag] = [event.value for event in events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('lr')\n",
    "plt.title('adamw lr')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\n",
    "plt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train/val rmse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best_val_loss', min(scalars['val_loss']))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
